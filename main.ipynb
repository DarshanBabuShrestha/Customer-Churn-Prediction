{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a41a7b",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction using Machine Learning\n",
    "\n",
    "This notebook demonstrates a complete machine learning pipeline for predicting customer churn using scikit-learn and pandas. The workflow includes data loading, preprocessing, exploratory data analysis (EDA), model training, evaluation, and model export.\n",
    "\n",
    "**Goals:**\n",
    "1. Load and preprocess the dataset.\n",
    "2. Handle missing or categorical data appropriately.\n",
    "3. Perform exploratory data analysis (EDA) with plots (Matplotlib or Seaborn).\n",
    "4. Encode categorical variables and scale numeric features.\n",
    "5. Split the data into training and testing sets.\n",
    "6. Train at least three classification models:\n",
    "   - Logistic Regression\n",
    "   - Random Forest\n",
    "   - XGBoost (optional)\n",
    "7. Evaluate all models using accuracy, precision, recall, F1 score, and ROC AUC.\n",
    "8. Plot confusion matrix and ROC curves for each model.\n",
    "9. Select the best model based on performance.\n",
    "10. Optionally, export the final model as a .pkl file using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94796f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python313/python3.13t.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d372ea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.13.2)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/babud/Summer 2025/AI4ALL/DarshanProject/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.13.2)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/babud/Summer 2025/AI4ALL/DarshanProject/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.13.2)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/babud/Summer 2025/AI4ALL/DarshanProject/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822710d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python313/python3.13t.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb524f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51916f8b",
   "metadata": {},
   "source": [
    "## Data Overview and Initial Exploration\n",
    "\n",
    "Let's explore the dataset structure, check for missing values, and understand the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4a057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723a3cb",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's visualize the distribution of key features and the target variable (Churn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Churn', data=df)\n",
    "plt.title('Churn Distribution')\n",
    "plt.show()\n",
    "\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "df[num_cols].hist(figsize=(12, 8), bins=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3999c6e",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We will handle missing values, encode categorical variables, and scale numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Drop customerID if present\n",
    "    if 'customerID' in df.columns:\n",
    "        df = df.drop('customerID', axis=1)\n",
    "    \n",
    "    # Fill missing values for numeric columns with median\n",
    "    for col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    # Fill missing values for categorical columns with mode\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if col != 'Churn':\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "    # Encode target\n",
    "    df['Churn'] = df['Churn'].map({'Yes':1, 'No':0})\n",
    "    \n",
    "    # Scale numeric features\n",
    "    scaler = StandardScaler()\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    return df\n",
    "\n",
    "df_processed = preprocess_data(df.copy())\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088156d",
   "metadata": {},
   "source": [
    "## Train-Test Split and Model Training\n",
    "\n",
    "We will split the data and train Logistic Regression, Random Forest, and (optionally) XGBoost models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data and train models\n",
    "X = df_processed.drop('Churn', axis=1)\n",
    "y = df_processed['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_available = True\n",
    "except ImportError:\n",
    "    xgb_available = False\n",
    "    print('XGBoost not installed. Skipping XGBoost model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f07c1a",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We will evaluate all models using accuracy, precision, recall, F1 score, ROC AUC, confusion matrix, and ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6081045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models and plot confusion matrix and ROC curves\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, 'predict_proba') else None\n",
    "    print(f\"\\n{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "    if y_proba is not None:\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f\"ROC AUC: {auc:.4f}\")\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})')\n",
    "    else:\n",
    "        print(\"No probability scores available for ROC curve.\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(logreg, X_test, y_test, 'Logistic Regression')\n",
    "evaluate_model(rf, X_test, y_test, 'Random Forest')\n",
    "if 'xgb_available' in locals() and xgb_available:\n",
    "    evaluate_model(xgb, X_test, y_test, 'XGBoost')\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db07200",
   "metadata": {},
   "source": [
    "## Model Selection and Export\n",
    "\n",
    "Select the best model based on evaluation metrics and export it as a .pkl file using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d4b8ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '\"c:/Program Files/Python313/python3.13t.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "best_model = rf  \n",
    "joblib.dump(best_model, 'best_churn_model.pkl')\n",
    "print('Best model exported as best_churn_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
